{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t2/qcdrdtq16v1d93n5hnwd7lkw0000gn/T/ipykernel_27827/1424333365.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 files belonging to 7 classes.\n",
      "Found 7178 files belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define paths\n",
    "train_dir = \"dataset/train\"\n",
    "test_dir = \"dataset/test\"\n",
    "\n",
    "# Parameters\n",
    "batch_size = 64\n",
    "img_height = 48\n",
    "img_width = 48\n",
    "\n",
    "# Load train dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Load test dataset\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    color_mode=\"grayscale\",\n",
    "    batch_size=batch_size,\n",
    "    image_size=(img_height, img_width),\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Normalize the pixel values\n",
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dual_path_cnn(input_shape, num_classes):\n",
    "    inputs = tf.keras.Input(shape=input_shape)\n",
    "\n",
    "    # Main path\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Residual path\n",
    "    residual = layers.Conv2D(64, (1, 1), padding='same', activation='relu')(inputs)\n",
    "    residual = layers.BatchNormalization()(residual)\n",
    "    residual = layers.MaxPooling2D((2, 2))(residual)  # Apply max pooling to match dimensions\n",
    "\n",
    "    # Combine paths\n",
    "    combined = layers.Add()([x, residual])\n",
    "    combined = layers.ReLU()(combined)\n",
    "\n",
    "    # Further layers\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(combined)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    # Flatten and dense layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "input_shape = (img_height, img_width, 1)  # Grayscale images\n",
    "num_classes = 7\n",
    "model = dual_path_cnn(input_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 2.0302 - accuracy: 0.2432 - val_loss: 3.1401 - val_accuracy: 0.2487\n",
      "Epoch 2/50\n",
      "449/449 [==============================] - 70s 155ms/step - loss: 1.8129 - accuracy: 0.2501 - val_loss: 1.7337 - val_accuracy: 0.2469\n",
      "Epoch 3/50\n",
      "449/449 [==============================] - 73s 162ms/step - loss: 1.7519 - accuracy: 0.2511 - val_loss: 1.6943 - val_accuracy: 0.2834\n",
      "Epoch 4/50\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 1.7219 - accuracy: 0.2671 - val_loss: 1.7039 - val_accuracy: 0.3172\n",
      "Epoch 5/50\n",
      "449/449 [==============================] - 70s 156ms/step - loss: 1.6967 - accuracy: 0.2805 - val_loss: 1.6647 - val_accuracy: 0.3044\n",
      "Epoch 6/50\n",
      "449/449 [==============================] - 67s 149ms/step - loss: 1.6869 - accuracy: 0.2814 - val_loss: 1.6529 - val_accuracy: 0.3206\n",
      "Epoch 7/50\n",
      "449/449 [==============================] - 74s 164ms/step - loss: 1.6684 - accuracy: 0.2885 - val_loss: 1.7065 - val_accuracy: 0.2926\n",
      "Epoch 8/50\n",
      "449/449 [==============================] - 68s 151ms/step - loss: 1.6610 - accuracy: 0.2910 - val_loss: 1.6699 - val_accuracy: 0.2784\n",
      "Epoch 9/50\n",
      "449/449 [==============================] - 71s 158ms/step - loss: 1.6500 - accuracy: 0.2967 - val_loss: 1.6650 - val_accuracy: 0.3137\n",
      "Epoch 10/50\n",
      "449/449 [==============================] - 71s 157ms/step - loss: 1.6436 - accuracy: 0.3031 - val_loss: 1.6155 - val_accuracy: 0.3359\n",
      "Epoch 11/50\n",
      "449/449 [==============================] - 66s 147ms/step - loss: 1.6200 - accuracy: 0.3095 - val_loss: 1.6637 - val_accuracy: 0.3031\n",
      "Epoch 12/50\n",
      "449/449 [==============================] - 66s 146ms/step - loss: 1.6188 - accuracy: 0.3089 - val_loss: 1.6611 - val_accuracy: 0.3058\n",
      "Epoch 13/50\n",
      "449/449 [==============================] - 63s 140ms/step - loss: 1.6322 - accuracy: 0.3081 - val_loss: 1.6932 - val_accuracy: 0.2962\n",
      "Epoch 14/50\n",
      "449/449 [==============================] - 62s 139ms/step - loss: 1.6218 - accuracy: 0.3116 - val_loss: 1.6084 - val_accuracy: 0.3346\n",
      "Epoch 15/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.6040 - accuracy: 0.3153 - val_loss: 1.6182 - val_accuracy: 0.3285\n",
      "Epoch 16/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.5952 - accuracy: 0.3174 - val_loss: 1.6393 - val_accuracy: 0.3100\n",
      "Epoch 17/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.5850 - accuracy: 0.3236 - val_loss: 1.6323 - val_accuracy: 0.3247\n",
      "Epoch 18/50\n",
      "449/449 [==============================] - 63s 139ms/step - loss: 1.5784 - accuracy: 0.3274 - val_loss: 1.5996 - val_accuracy: 0.3565\n",
      "Epoch 19/50\n",
      "449/449 [==============================] - 61s 136ms/step - loss: 1.5720 - accuracy: 0.3303 - val_loss: 1.6684 - val_accuracy: 0.3300\n",
      "Epoch 20/50\n",
      "449/449 [==============================] - 63s 140ms/step - loss: 1.5553 - accuracy: 0.3390 - val_loss: 1.5802 - val_accuracy: 0.3700\n",
      "Epoch 21/50\n",
      "449/449 [==============================] - 61s 136ms/step - loss: 1.5460 - accuracy: 0.3439 - val_loss: 1.5961 - val_accuracy: 0.3695\n",
      "Epoch 22/50\n",
      "449/449 [==============================] - 63s 139ms/step - loss: 1.5416 - accuracy: 0.3434 - val_loss: 1.6253 - val_accuracy: 0.3764\n",
      "Epoch 23/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.5264 - accuracy: 0.3488 - val_loss: 1.5771 - val_accuracy: 0.3706\n",
      "Epoch 24/50\n",
      "449/449 [==============================] - 64s 141ms/step - loss: 1.5163 - accuracy: 0.3528 - val_loss: 1.5869 - val_accuracy: 0.3512\n",
      "Epoch 25/50\n",
      "449/449 [==============================] - 63s 141ms/step - loss: 1.5078 - accuracy: 0.3581 - val_loss: 1.5733 - val_accuracy: 0.3695\n",
      "Epoch 26/50\n",
      "449/449 [==============================] - 62s 139ms/step - loss: 1.5007 - accuracy: 0.3583 - val_loss: 1.5745 - val_accuracy: 0.3677\n",
      "Epoch 27/50\n",
      "449/449 [==============================] - 64s 142ms/step - loss: 1.4933 - accuracy: 0.3584 - val_loss: 1.7651 - val_accuracy: 0.3703\n",
      "Epoch 28/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.4905 - accuracy: 0.3603 - val_loss: 1.5866 - val_accuracy: 0.3706\n",
      "Epoch 29/50\n",
      "449/449 [==============================] - 62s 139ms/step - loss: 1.4803 - accuracy: 0.3635 - val_loss: 1.5593 - val_accuracy: 0.3841\n",
      "Epoch 30/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.4732 - accuracy: 0.3640 - val_loss: 1.5966 - val_accuracy: 0.3731\n",
      "Epoch 31/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.4663 - accuracy: 0.3672 - val_loss: 1.5650 - val_accuracy: 0.3696\n",
      "Epoch 32/50\n",
      "449/449 [==============================] - 63s 141ms/step - loss: 1.4636 - accuracy: 0.3668 - val_loss: 1.5820 - val_accuracy: 0.3788\n",
      "Epoch 33/50\n",
      "449/449 [==============================] - 63s 141ms/step - loss: 1.4499 - accuracy: 0.3732 - val_loss: 1.5546 - val_accuracy: 0.3849\n",
      "Epoch 34/50\n",
      "449/449 [==============================] - 63s 140ms/step - loss: 1.4511 - accuracy: 0.3733 - val_loss: 1.6714 - val_accuracy: 0.3636\n",
      "Epoch 35/50\n",
      "449/449 [==============================] - 62s 138ms/step - loss: 1.4536 - accuracy: 0.3728 - val_loss: 1.5724 - val_accuracy: 0.3699\n",
      "Epoch 36/50\n",
      "449/449 [==============================] - 62s 139ms/step - loss: 1.4455 - accuracy: 0.3742 - val_loss: 1.5732 - val_accuracy: 0.3696\n",
      "Epoch 37/50\n",
      "449/449 [==============================] - 62s 139ms/step - loss: 1.4382 - accuracy: 0.3783 - val_loss: 1.5732 - val_accuracy: 0.3628\n",
      "Epoch 38/50\n",
      "449/449 [==============================] - 62s 139ms/step - loss: 1.4350 - accuracy: 0.3767 - val_loss: 1.5997 - val_accuracy: 0.3470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    validation_data=test_ds,\n",
    "                    epochs=50,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)])\n",
    "\n",
    "# Save the model\n",
    "model.save('fer_ducnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "val_loss, val_accuracy = model.evaluate(test_ds)\n",
    "print(f'Validation accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Model Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Model Loss')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
